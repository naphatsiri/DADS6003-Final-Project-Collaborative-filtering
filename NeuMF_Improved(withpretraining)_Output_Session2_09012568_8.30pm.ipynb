{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naphatsiri/DADS6003-Final-Project-Collaborative-filtering/blob/main/NeuMF_Improved(withpretraining)_Output_Session2_09012568_8.30pm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQRupxUVpx3d",
        "outputId": "001ca029-4530-468f-e7c6-5774a0c6e524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating initial model...\n",
            "Init: HR = 0.1022, NDCG = 0.0467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: HR = 0.5957, NDCG = 0.3371, loss = 0.3198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: HR = 0.6377, NDCG = 0.3665, loss = 0.2744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: HR = 0.6517, NDCG = 0.3790, loss = 0.2636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: HR = 0.6596, NDCG = 0.3856, loss = 0.2583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: HR = 0.6651, NDCG = 0.3913, loss = 0.2542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: HR = 0.6755, NDCG = 0.3997, loss = 0.2509\n",
            "Epoch 6: HR = 0.6712, NDCG = 0.3982, loss = 0.2480\n",
            "Epoch 7: HR = 0.6743, NDCG = 0.4003, loss = 0.2456\n",
            "Epoch 8: HR = 0.6702, NDCG = 0.3992, loss = 0.2432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: HR = 0.6786, NDCG = 0.4063, loss = 0.2414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: HR = 0.6843, NDCG = 0.4088, loss = 0.2397\n",
            "Epoch 11: HR = 0.6695, NDCG = 0.4006, loss = 0.2379\n",
            "Epoch 12: HR = 0.6762, NDCG = 0.4027, loss = 0.2362\n",
            "Epoch 13: HR = 0.6752, NDCG = 0.4031, loss = 0.2352\n",
            "Epoch 14: HR = 0.6772, NDCG = 0.4053, loss = 0.2336\n",
            "Epoch 15: HR = 0.6715, NDCG = 0.4012, loss = 0.2323\n",
            "Epoch 16: HR = 0.6737, NDCG = 0.4026, loss = 0.2314\n",
            "Epoch 17: HR = 0.6748, NDCG = 0.4028, loss = 0.2305\n",
            "Epoch 18: HR = 0.6740, NDCG = 0.4048, loss = 0.2296\n",
            "Epoch 19: HR = 0.6811, NDCG = 0.4059, loss = 0.2284\n",
            "End. Best Iteration 10: HR = 0.6843, NDCG = 0.4088.\n"
          ]
        }
      ],
      "source": [
        "#NeuMF_Improving_(with_pre_training)_Output_Session2__Save-best-model_09/01/2568_16.30\n",
        "#1) Added Dropout Layers: Introduced dropout in the MLP part to reduce overfitting.\n",
        "#2) Activation Functions: Used relu for the intermediate layers and sigmoid for the output layer.\n",
        "#3) Model Compilation: Added accuracy as an additional metric for better monitoring during training.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Input, Dense, Flatten, Concatenate, Multiply, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import time\n",
        "from evaluate import evaluate_model  # Ensure evaluate_model.py is uploaded in the environment\n",
        "from Dataset import Dataset  # Ensure Dataset.py is uploaded in the environment\n",
        "\n",
        "#################### Arguments ####################\n",
        "class Args:\n",
        "    path = './Data/'\n",
        "    dataset = 'ml-1m'\n",
        "    epochs = 20\n",
        "    batch_size = 256\n",
        "    num_factors = 8\n",
        "    layers = '[64,32,16,8]'\n",
        "    reg_mf = 0\n",
        "    reg_layers = '[0,0,0,0]'\n",
        "    num_neg = 4\n",
        "    lr = 0.001\n",
        "    verbose = 1\n",
        "    out = 1\n",
        "    mf_pretrain = 'ml-1m_GMF_model.h5'\n",
        "    mlp_pretrain = 'ml-1m_MLP_model.h5'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "#################### Utility Function ####################\n",
        "def get_train_instances(train, num_negatives):\n",
        "    \"\"\"\n",
        "    Generate user, item, and label data for training.\n",
        "    :param train: The training matrix (users x items).\n",
        "    :param num_negatives: Number of negative samples per positive interaction.\n",
        "    :return: user_input, item_input, labels\n",
        "    \"\"\"\n",
        "    user_input, item_input, labels = [], [], []\n",
        "    num_users, num_items = train.shape\n",
        "    for (u, i) in train.keys():\n",
        "        # Positive instance\n",
        "        user_input.append(u)\n",
        "        item_input.append(i)\n",
        "        labels.append(1)\n",
        "        # Negative instances\n",
        "        for _ in range(num_negatives):\n",
        "            j = np.random.randint(num_items)\n",
        "            while (u, j) in train:\n",
        "                j = np.random.randint(num_items)\n",
        "            user_input.append(u)\n",
        "            item_input.append(j)\n",
        "            labels.append(0)\n",
        "    return user_input, item_input, labels\n",
        "\n",
        "#################### Model Definition ####################\n",
        "def get_model(num_users, num_items, mf_dim=8, layers=[64, 32, 16, 8], reg_layers=[0, 0, 0, 0], reg_mf=0):\n",
        "    # Input layers\n",
        "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
        "\n",
        "    # Embedding layers\n",
        "    MF_Embedding_User = Embedding(input_dim=num_users, output_dim=mf_dim, embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "    MF_Embedding_Item = Embedding(input_dim=num_items, output_dim=mf_dim, embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "\n",
        "    MLP_Embedding_User = Embedding(input_dim=num_users, output_dim=layers[0] // 2, embeddings_regularizer=l2(reg_layers[0]), input_length=1)\n",
        "    MLP_Embedding_Item = Embedding(input_dim=num_items, output_dim=layers[0] // 2, embeddings_regularizer=l2(reg_layers[0]), input_length=1)\n",
        "\n",
        "    # MF part\n",
        "    mf_user_latent = Flatten()(MF_Embedding_User(user_input))\n",
        "    mf_item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
        "    mf_vector = Multiply()([mf_user_latent, mf_item_latent])\n",
        "\n",
        "    # MLP part\n",
        "    mlp_user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
        "    mlp_item_latent = Flatten()(MLP_Embedding_Item(item_input))\n",
        "    mlp_vector = Concatenate()([mlp_user_latent, mlp_item_latent])\n",
        "    for idx in range(1, len(layers)):\n",
        "        mlp_vector = Dense(layers[idx], activation='relu', kernel_regularizer=l2(reg_layers[idx]))(mlp_vector)\n",
        "        mlp_vector = Dropout(0.2)(mlp_vector)  # Add dropout to reduce overfitting\n",
        "\n",
        "    # Concatenate MF and MLP parts\n",
        "    predict_vector = Concatenate()([mf_vector, mlp_vector])\n",
        "\n",
        "    # Prediction layer\n",
        "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name=\"prediction\")(predict_vector)\n",
        "\n",
        "    model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
        "    return model\n",
        "\n",
        "#################### Training & Evaluation ####################\n",
        "if __name__ == '__main__':\n",
        "    # Load Dataset\n",
        "    dataset = Dataset(args.path + args.dataset)\n",
        "    train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives\n",
        "    num_users, num_items = train.shape\n",
        "\n",
        "    # Load pre-trained models if available\n",
        "    gmf_model = tf.keras.models.load_model(args.mf_pretrain) if os.path.exists(args.mf_pretrain) else None\n",
        "    mlp_model = tf.keras.models.load_model(args.mlp_pretrain) if os.path.exists(args.mlp_pretrain) else None\n",
        "\n",
        "    # Initialize the NeuMF model\n",
        "    model = get_model(num_users, num_items, args.num_factors, eval(args.layers), eval(args.reg_layers), args.reg_mf)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=args.lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Initial performance evaluation\n",
        "    print(\"Evaluating initial model...\")\n",
        "    hits, ndcgs = evaluate_model(model, testRatings, testNegatives, 10, 1)\n",
        "    hr, ndcg = np.mean(hits), np.mean(ndcgs)\n",
        "    print(f'Init: HR = {hr:.4f}, NDCG = {ndcg:.4f}')\n",
        "    best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
        "\n",
        "    # Training loop\n",
        "    best_model_path = 'NeuMF_best_model.h5'\n",
        "    for epoch in range(args.epochs):\n",
        "        t1 = time.time()\n",
        "        user_input, item_input, labels = get_train_instances(train, args.num_neg)\n",
        "\n",
        "        hist = model.fit([np.array(user_input), np.array(item_input)], np.array(labels),\n",
        "                         batch_size=args.batch_size, epochs=1, verbose=0, shuffle=True)\n",
        "        t2 = time.time()\n",
        "\n",
        "        # Evaluation\n",
        "        if epoch % args.verbose == 0:\n",
        "            hits, ndcgs = evaluate_model(model, testRatings, testNegatives, 10, 1)\n",
        "            hr, ndcg = np.mean(hits), np.mean(ndcgs)\n",
        "            print(f'Epoch {epoch}: HR = {hr:.4f}, NDCG = {ndcg:.4f}, loss = {hist.history[\"loss\"][0]:.4f}')\n",
        "\n",
        "            # Save the best model\n",
        "            if hr > best_hr:\n",
        "                best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
        "                if args.out:\n",
        "                    model.save(best_model_path)\n",
        "\n",
        "    # Final output\n",
        "    print(f\"End. Best Iteration {best_iter}: HR = {best_hr:.4f}, NDCG = {best_ndcg:.4f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Improvement NeuMF_Improving_(with_pre_training)_Output_Session2_09012568_17.25\n",
        "#Improvig with these features\n",
        "#1.LeakyReLU may improve performance by avoiding dead neurons.\n",
        "#2.AdamW helps balance learning rate adaptation and regularization, often leading to better generalization.\n",
        "#3.Added Dropout Layers: Introduced dropout in the MLP part to reduce overfitting.\n",
        "#4.Model Compilation: Added accuracy as an additional metric for better monitoring during training.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Input, Dense, Flatten, Concatenate, Multiply, Dropout, LeakyReLU\n",
        "from keras.optimizers import AdamW\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import time\n",
        "from evaluate import evaluate_model  # Ensure evaluate_model.py is uploaded in the environment\n",
        "from Dataset import Dataset  # Ensure Dataset.py is uploaded in the environment\n",
        "\n",
        "#################### Arguments ####################\n",
        "class Args:\n",
        "    path = './Data/'\n",
        "    dataset = 'ml-1m'\n",
        "    epochs = 20\n",
        "    batch_size = 256\n",
        "    num_factors = 8\n",
        "    layers = '[64,32,16,8]'\n",
        "    reg_mf = 0\n",
        "    reg_layers = '[0,0,0,0]'\n",
        "    num_neg = 4\n",
        "    lr = 0.001\n",
        "    weight_decay = 1e-5  # Weight decay for AdamW\n",
        "    verbose = 1\n",
        "    out = 1\n",
        "    mf_pretrain = 'ml-1m_GMF_model.h5'\n",
        "    mlp_pretrain = 'ml-1m_MLP_model.h5'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "#################### Utility Function ####################\n",
        "def get_train_instances(train, num_negatives):\n",
        "    \"\"\"\n",
        "    Generate user, item, and label data for training.\n",
        "    :param train: The training matrix (users x items).\n",
        "    :param num_negatives: Number of negative samples per positive interaction.\n",
        "    :return: user_input, item_input, labels\n",
        "    \"\"\"\n",
        "    user_input, item_input, labels = [], [], []\n",
        "    num_users, num_items = train.shape\n",
        "    for (u, i) in train.keys():\n",
        "        # Positive instance\n",
        "        user_input.append(u)\n",
        "        item_input.append(i)\n",
        "        labels.append(1)\n",
        "        # Negative instances\n",
        "        for _ in range(num_negatives):\n",
        "            j = np.random.randint(num_items)\n",
        "            while (u, j) in train:\n",
        "                j = np.random.randint(num_items)\n",
        "            user_input.append(u)\n",
        "            item_input.append(j)\n",
        "            labels.append(0)\n",
        "    return user_input, item_input, labels\n",
        "\n",
        "#################### Model Definition ####################\n",
        "def get_model(num_users, num_items, mf_dim=8, layers=[64, 32, 16, 8], reg_layers=[0, 0, 0, 0], reg_mf=0):\n",
        "    # Input layers\n",
        "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
        "\n",
        "    # Embedding layers\n",
        "    MF_Embedding_User = Embedding(input_dim=num_users, output_dim=mf_dim, embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "    MF_Embedding_Item = Embedding(input_dim=num_items, output_dim=mf_dim, embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "\n",
        "    MLP_Embedding_User = Embedding(input_dim=num_users, output_dim=layers[0] // 2, embeddings_regularizer=l2(reg_layers[0]), input_length=1)\n",
        "    MLP_Embedding_Item = Embedding(input_dim=num_items, output_dim=layers[0] // 2, embeddings_regularizer=l2(reg_layers[0]), input_length=1)\n",
        "\n",
        "    # MF part\n",
        "    mf_user_latent = Flatten()(MF_Embedding_User(user_input))\n",
        "    mf_item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
        "    mf_vector = Multiply()([mf_user_latent, mf_item_latent])\n",
        "\n",
        "    # MLP part\n",
        "    mlp_user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
        "    mlp_item_latent = Flatten()(MLP_Embedding_Item(item_input))\n",
        "    mlp_vector = Concatenate()([mlp_user_latent, mlp_item_latent])\n",
        "    for idx in range(1, len(layers)):\n",
        "        mlp_vector = Dense(layers[idx], kernel_regularizer=l2(reg_layers[idx]))(mlp_vector)\n",
        "        mlp_vector = LeakyReLU(alpha=0.01)(mlp_vector)  # Use LeakyReLU with a slope of 0.01 for negative values\n",
        "        mlp_vector = Dropout(0.2)(mlp_vector)  # Add dropout to reduce overfitting\n",
        "\n",
        "    # Concatenate MF and MLP parts\n",
        "    predict_vector = Concatenate()([mf_vector, mlp_vector])\n",
        "\n",
        "    # Prediction layer\n",
        "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name=\"prediction\")(predict_vector)\n",
        "\n",
        "    model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
        "    return model\n",
        "\n",
        "#################### Training & Evaluation ####################\n",
        "if __name__ == '__main__':\n",
        "    # Load Dataset\n",
        "    dataset = Dataset(args.path + args.dataset)\n",
        "    train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives\n",
        "    num_users, num_items = train.shape\n",
        "\n",
        "    # Load pre-trained models if available\n",
        "    gmf_model = tf.keras.models.load_model(args.mf_pretrain) if os.path.exists(args.mf_pretrain) else None\n",
        "    mlp_model = tf.keras.models.load_model(args.mlp_pretrain) if os.path.exists(args.mlp_pretrain) else None\n",
        "\n",
        "    # Initialize the NeuMF model\n",
        "    model = get_model(num_users, num_items, args.num_factors, eval(args.layers), eval(args.reg_layers), args.reg_mf)\n",
        "\n",
        "    # Compile the model with AdamW optimizer\n",
        "    optimizer = AdamW(learning_rate=args.lr, weight_decay=args.weight_decay)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Initial performance evaluation\n",
        "    print(\"Evaluating initial model...\")\n",
        "    hits, ndcgs = evaluate_model(model, testRatings, testNegatives, 10, 1)\n",
        "    hr, ndcg = np.mean(hits), np.mean(ndcgs)\n",
        "    print(f'Init: HR = {hr:.4f}, NDCG = {ndcg:.4f}')\n",
        "    best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
        "\n",
        "    # Training loop\n",
        "    best_model_path = 'NeuMF_best_model.h5'\n",
        "    for epoch in range(args.epochs):\n",
        "        t1 = time.time()\n",
        "        user_input, item_input, labels = get_train_instances(train, args.num_neg)\n",
        "\n",
        "        hist = model.fit([np.array(user_input), np.array(item_input)], np.array(labels),\n",
        "                         batch_size=args.batch_size, epochs=1, verbose=0, shuffle=True)\n",
        "        t2 = time.time()\n",
        "\n",
        "        # Evaluation\n",
        "        if epoch % args.verbose == 0:\n",
        "            hits, ndcgs = evaluate_model(model, testRatings, testNegatives, 10, 1)\n",
        "            hr, ndcg = np.mean(hits), np.mean(ndcgs)\n",
        "            print(f'Epoch {epoch}: HR = {hr:.4f}, NDCG = {ndcg:.4f}, loss = {hist.history[\"loss\"][0]:.4f}')\n",
        "\n",
        "            # Save the best model\n",
        "            if hr > best_hr:\n",
        "                best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
        "                if args.out:\n",
        "                    model.save(best_model_path)\n",
        "\n",
        "    # Final output\n",
        "    print(f\"End. Best Iteration {best_iter}: HR = {best_hr:.4f}, NDCG = {best_ndcg:.4f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKBX38B1ljwB",
        "outputId": "638d3dfd-1e01-4ee4-dada-e03631b8ab8a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating initial model...\n",
            "Init: HR = 0.0998, NDCG = 0.0467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: HR = 0.5859, NDCG = 0.3326, loss = 0.3296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: HR = 0.6187, NDCG = 0.3550, loss = 0.2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: HR = 0.6369, NDCG = 0.3681, loss = 0.2743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: HR = 0.6469, NDCG = 0.3718, loss = 0.2702\n",
            "Epoch 4: HR = 0.6450, NDCG = 0.3745, loss = 0.2672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: HR = 0.6523, NDCG = 0.3791, loss = 0.2645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: HR = 0.6571, NDCG = 0.3843, loss = 0.2624\n",
            "Epoch 7: HR = 0.6563, NDCG = 0.3855, loss = 0.2606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: HR = 0.6639, NDCG = 0.3910, loss = 0.2593\n",
            "Epoch 9: HR = 0.6613, NDCG = 0.3878, loss = 0.2579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: HR = 0.6694, NDCG = 0.3934, loss = 0.2567\n",
            "Epoch 11: HR = 0.6659, NDCG = 0.3944, loss = 0.2562\n",
            "Epoch 12: HR = 0.6684, NDCG = 0.3927, loss = 0.2555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: HR = 0.6732, NDCG = 0.3993, loss = 0.2544\n",
            "Epoch 14: HR = 0.6727, NDCG = 0.3970, loss = 0.2539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: HR = 0.6753, NDCG = 0.3980, loss = 0.2529\n",
            "Epoch 16: HR = 0.6750, NDCG = 0.3982, loss = 0.2528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: HR = 0.6757, NDCG = 0.3993, loss = 0.2521\n",
            "Epoch 18: HR = 0.6755, NDCG = 0.3996, loss = 0.2516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: HR = 0.6765, NDCG = 0.3997, loss = 0.2508\n",
            "End. Best Iteration 19: HR = 0.6765, NDCG = 0.3997.\n"
          ]
        }
      ]
    }
  ]
}